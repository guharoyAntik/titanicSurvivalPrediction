# Titanice Survival Prediction

This notebook is my solution to the Kaggle Machine Learning Competition which can be found [here](https://www.kaggle.com/c/titanic).

## Abstract
The sinking of the Titanic is one of the most infamous shipwrecks in history.

On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.

While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.
The challenge is to build a predictive model that answers the question: “what sorts of people were more likely to survive?” using passenger data (ie name, age, gender, socio-economic class, etc). 

## Workflow

Data Preparation
1. Importing data
2. Analysing features
3. Plotting visualizations
4. Data cleaning and standardisation

Model selection and prediction
1. Trying different machine learning algorithms
    * Support Vector Machines
    * KNN
    * Logistic Regression
    * Random Forest
    * Naive Bayes
    * Perceptron
    * Linear SVC
    * Decision Tree
    * Stochastic Gradient Descent
    * Gradient Boosting Classifier
2. Comparing performance of models
3. Prediction and submission

## Conclusion

My final submission using Gradient Boosting Classifier gave me a score of **0.77272** on Kaggle leaderboards.
